{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN_GP-CIFAR10\n",
    "# Sadegh Sadeghi Tabas\n",
    "# sadeghs@clemson.edu\n",
    "\n",
    "# Requirement Package: Tensorflow 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import log\n",
    "from numpy.random import shuffle\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and extract the CIFAR10 dataset\n",
    "\n",
    "\"\"\"\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "        \n",
    "with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "    urlretrieve('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "        'cifar-10-python.tar.gz', pbar.hook)\n",
    "        \n",
    "with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\"\"\"\n",
    "\n",
    "# the cifar10 dataset ==>> 0:airplane 1:automobile 2:bird 3:cat 4:deer 5:dog 6:fox 7:horse 8:ship 9:truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuction to create the required directories\n",
    "def createDirectories():\n",
    "    if not os.path.isdir('checkpoint_wgan_GP'):\n",
    "        os.mkdir('checkpoint_wgan_GP')\n",
    "    if not os.path.isdir('trainingLog_wgan_GP'):\n",
    "        os.mkdir('trainingLog_wgan_GP')\n",
    "    if not os.path.isdir('images_wgan_GP'):\n",
    "        os.mkdir('images_wgan_GP')\n",
    "    if not os.path.isdir('training_data'):\n",
    "        os.mkdir('training_data')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show output images\n",
    "def showImg(img,index,nums):\n",
    "    fig, axes = plt.subplots(figsize=( nums+2,len(index)+2), nrows=len(index), ncols=nums, sharey=True, sharex=True)\n",
    "    if len(index) == 1:\n",
    "        for ax,img in zip(axes.flatten(),img[index[0]]):\n",
    "            ax.xaxis.set_visible(False)\n",
    "            ax.yaxis.set_visible(False)\n",
    "            ax.imshow(img)\n",
    "    else:\n",
    "        for ax_row, idx in zip(axes, index):\n",
    "            img_row = img[idx][0:nums]\n",
    "            for image, ax in zip(img_row,ax_row):\n",
    "                ax.xaxis.set_visible(False)\n",
    "                ax.yaxis.set_visible(False)\n",
    "                ax.imshow(imag)\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization\n",
    "def batch_norm(data):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    minmax = MinMaxScaler()\n",
    "    data = minmax.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataBatch(data, label, dataSize, labelSize, isShuffle, batchSize):\n",
    "    capacity = 500 \n",
    "    data.set_shape(dataSize)\n",
    "    label.set_shape(labelSize)\n",
    "    min_after_dequeue = 2 * batchSize \n",
    "\n",
    "    if isShuffle:\n",
    "        [data_batch, label_batch] = tf.train.shuffle_batch([data,label],batch_size=batchSize,capacity=capacity,\n",
    "                                                       min_after_dequeue=min_after_dequeue)\n",
    "    else:\n",
    "        [data_batch,label_batch] = tf.train.batch([data,label],batch_size=batchSize,capacity=capacity)\n",
    "\n",
    "    return [data_batch, label_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read from training data\n",
    "def readTraining(sameName, isShuffle, datatype, labeltype, isMultithreading):\n",
    "    fileslist = tf.train.match_filenames_once(sameName)\n",
    "    filename_queue = tf.train.string_input_producer(fileslist,shuffle=isShuffle)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialization = reader.read(filename_queue)\n",
    "    if isMultithreading:\n",
    "        qr = tf.train.QueueRunner(filename_queue, [serialization] * 7)\n",
    "        tf.train.add_queue_runner(qr)\n",
    "    features = tf.parse_single_example(\n",
    "        serialization,\n",
    "        features={\n",
    "            \"data\": tf.FixedLenFeature([],tf.string), \n",
    "            \"label\": tf.FixedLenFeature([],tf.string) \n",
    "        })\n",
    "    data = tf.decode_raw(features[\"data\"], datatype)\n",
    "    label = tf.decode_raw(features['label'], labeltype)\n",
    "\n",
    "    return [data,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def Bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to write the record\n",
    "def saveTrainingData(data, label, filename, npart):\n",
    "    dir, file = os.path.split(filename)\n",
    "    if not os.path.isdir(dir):\n",
    "        print('build directory..'%(dir))\n",
    "        os.mkdir(dir)\n",
    "    index = np.int32(np.linspace(0,data.shape[0],npart+1))\n",
    "\n",
    "    for i in range(npart):\n",
    "        suffix = \"-%.1d-of-%.1d\"%(i+1,npart)\n",
    "        newname = filename + suffix\n",
    "        writer = tf.python_io.TFRecordWriter(newname)\n",
    "        for j in range(index[i],index[i+1]):\n",
    "            data_to_string = data[j].tobytes()\n",
    "            label_to_string = label[j].tobytes()\n",
    "            feature = {\n",
    "                \"data\": Bytes_feature(data_to_string),\n",
    "                \"label\": Bytes_feature(label_to_string),\n",
    "            }\n",
    "            features = tf.train.Features(feature=feature) \n",
    "            example = tf.train.Example(features=features)\n",
    "            writer.write(example.SerializeToString())\n",
    "        writer.close()\n",
    "    fileSets = os .listdir(dir)\n",
    "    print(fileSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load CIFAR10 data\n",
    "def loadCifar10_class(cifarPath, kind):\n",
    "    fo = open(cifarPath, 'rb')\n",
    "    cifar10_dict  = pickle.load(fo, encoding='bytes')\n",
    "    cifar10_label = cifar10_dict.get(b'labels')\n",
    "    cifar10_data = cifar10_dict.get(b'data')\n",
    "    L = [label for label in cifar10_label if label == kind]\n",
    "    C = [cifar10_data[label[0]] for label in enumerate(cifar10_label) if label[1] == kind]\n",
    "    C = np.array(C)\n",
    "    L = np.array(L)\n",
    "    fo.close()\n",
    "    return C, L\n",
    "\n",
    "# read the whole CIFAR10 data\n",
    "def loadCifar10AllClasses(kind):\n",
    "    C, L = loadCifar10_class(r'./cifar-10-batches-py/data_batch_1', kind)\n",
    "    for i in range(2, 6):\n",
    "        filename = './/cifar-10-batches-py//data_batch_' + str(i)\n",
    "        data, label = loadCifar10_class(filename, kind)\n",
    "        C = np.concatenate((C, data))\n",
    "        L = np.concatenate((L, label))\n",
    "    return C, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scale the images\n",
    "def scaleImages(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_preprocess(data_batch):\n",
    "    batch = sess.run(data_batch)\n",
    "    batch_images = np.reshape(batch, [-1, 3, 32, 32]).transpose((0, 2, 3, 1))\n",
    "    batch_images = batch_images * 2 - 1\n",
    "    return  batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generative network\n",
    "def generative(z, channel, is_train=True):\n",
    "    with tf.variable_scope(\"generator\", reuse=(not is_train)):\n",
    "        layer1 = tf.layers.dense(z, 4 * 4 * 512)\n",
    "        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])\n",
    "        layer1 = tf.layers.batch_normalization(layer1, training=is_train,)\n",
    "        layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "        layer2 = tf.layers.conv2d_transpose(layer1, 256, 3, strides=2, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=is_train)\n",
    "        layer2 = tf.nn.relu(layer2)\n",
    "\n",
    "        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=is_train)\n",
    "        layer3 = tf.nn.relu(layer3)\n",
    "\n",
    "        layer4 = tf.layers.conv2d_transpose(layer3, 64, 3, strides=2, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        layer4 = tf.layers.batch_normalization(layer4, training=is_train)\n",
    "        layer4 = tf.nn.relu(layer4)\n",
    "\n",
    "        logits = tf.layers.conv2d_transpose(layer4, channel, 3, strides=1, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        outputs = tf.tanh(logits)\n",
    "        \n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminative network\n",
    "def discriminative(inputs_img, reuse=False, GAN = False, GP= True, alpha=0.2):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "\n",
    "        layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding='same')\n",
    "        if GP is False:\n",
    "            layer1 = tf.layers.batch_normalization(layer1, training=True)\n",
    "        layer1 = tf.nn.leaky_relu(layer1,alpha=alpha)\n",
    "\n",
    "        layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding='same')\n",
    "        if GP is False:\n",
    "            layer2 = tf.layers.batch_normalization(layer2, training=True)\n",
    "        layer2 = tf.nn.leaky_relu(layer2, alpha=alpha)\n",
    "\n",
    "        layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding='same')\n",
    "        if GP is False:\n",
    "            layer3 = tf.layers.batch_normalization(layer3, training=True)\n",
    "        layer3 = tf.nn.leaky_relu(layer3, alpha=alpha)\n",
    "        layer3 = tf.reshape(layer3, [-1, 4*4* 512])\n",
    "\n",
    "        logits = tf.layers.dense(layer3, 1)\n",
    "        if GAN:\n",
    "            outputs = None\n",
    "        else:\n",
    "            outputs = tf.sigmoid(logits)\n",
    "\n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please select the class of the cifar10 dataset that you want to run the GAN for it\n",
    "\n",
    "# 0 ==> airplaine\n",
    "# 1 ==> car\n",
    "# 2 ==> bird\n",
    "# 3 ==> cat\n",
    "# 4 ==> dear\n",
    "# 5 ==> dog\n",
    "# 6 ==> fox\n",
    "# 7 ==> horse\n",
    "# 8 ==> ship\n",
    "# 9 ==> truck\n",
    "\n",
    "createDirectories()\n",
    "\n",
    "# please put the class number in the function below\n",
    "C, L = loadCifar10AllClasses(1)\n",
    "C = batch_norm(C)\n",
    "\n",
    "# print sample images (real images) \n",
    "imgs = C[-11:-1].reshape(-1,3,32,32).transpose((0,2,3,1))\n",
    "fig, axes = plt.subplots(figsize=(20, 7), nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "for ax,img in zip(axes.flatten(),imgs):\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#save it as TFR\n",
    "saveTrainingData(C ,L, r'./training_data/class_1', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_shape = [-1,32,32,3]\n",
    "data_total = 6000 \n",
    "batch_size = 64\n",
    "noise_size = 128 \n",
    "max_iters = 40000\n",
    "learning_rate = 5e-5\n",
    "criticNUM = 5\n",
    "clip = [-0.1, 0.1]\n",
    "generateLog = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs data\n",
    "inputs_real = tf.placeholder(tf.float32, [None, real_shape[1], real_shape[2], real_shape[3]], name='inputs_real')\n",
    "inputs_noise = tf.placeholder(tf.float32, [None, noise_size], name='inputs_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generative network (g)\n",
    "_, g_outputs = generative(inputs_noise, real_shape[3], is_train=True)\n",
    "_, g_test = generative(inputs_noise, real_shape[3], is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminative network (d)\n",
    "d_logits_real, _ = discriminative(inputs_real,GAN=True)\n",
    "d_logits_fake, _ = discriminative(g_outputs,GAN=True,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for networks\n",
    "g_loss = tf.reduce_mean(-d_logits_fake)\n",
    "d_loss = tf.reduce_mean(d_logits_fake - d_logits_real)\n",
    "\n",
    "train_vars  = tf.trainable_variables()\n",
    "g_vars = [var for var in train_vars  if var.name.startswith(\"generator\")]\n",
    "d_vars = [var for var in train_vars  if var.name.startswith(\"discriminator\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer alg\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    g_train_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "    d_train_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip\n",
    "d_clip_opt = [tf.assign(var, tf.clip_by_value(var, clip[0], clip[1])) for var in d_vars]\n",
    "\n",
    "# read training data\n",
    "[data, label] = readTraining(sameName= r'./training_data/class_1-*',isShuffle= False,datatype= tf.float64, labeltype= tf.int64,isMultithreading= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "[data_batch, label_batch] = dataBatch(data,label,dataSize= 32*32*3,labelSize= 1, isShuffle= True, batchSize= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "saver = tf.train.Saver(var_list=[var for var in tf.trainable_variables() if var.name.startswith(\"generator\")], max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # start timing\n",
    "    time_start = time.time() \n",
    "    for epoch in range(max_iters):\n",
    "        epoch += 1\n",
    "        if epoch < 25 or epoch % 500 == 0:\n",
    "            critic_num = 100\n",
    "        else:\n",
    "            critic_num = criticNUM\n",
    "        for i in range(criticNUM):\n",
    "            batch_images = batch_preprocess(data_batch)  # images\n",
    "            batch_noise = np.random.normal(size=(batch_size, noise_size))  # noise(normal)\n",
    "            _ = sess.run(d_train_opt, feed_dict={inputs_real: batch_images, inputs_noise: batch_noise})\n",
    "            sess.run(d_clip_opt)\n",
    "\n",
    "        batch_images = batch_preprocess(data_batch)  # images\n",
    "        batch_noise = np.random.normal(size=(batch_size, noise_size))  # noise(normal)\n",
    "        _ = sess.run(g_train_opt, feed_dict={inputs_real: batch_images, inputs_noise: batch_noise})\n",
    "        if epoch % 5 == 1:\n",
    "            train_loss_d = d_loss.eval({inputs_real: batch_images, inputs_noise: batch_noise})\n",
    "            train_loss_g = g_loss.eval({inputs_real: batch_images, inputs_noise: batch_noise})\n",
    "            losses.append([train_loss_d, train_loss_g, epoch])\n",
    "            batch_noise = np.random.normal(size=(batch_size, noise_size))\n",
    "            gen_samples = sess.run(g_test, feed_dict={inputs_noise: batch_noise})\n",
    "            genLog = (gen_samples[0:11] + 1) / 2\n",
    "            generateLog.append(genLog)\n",
    "            print('epoch {}/{}...'.format(epoch,max_iters), \"Generator Loss: {:.4f}...\".format(train_loss_g), \"Discriminator Loss: {:.4f}...\".format(train_loss_d))\n",
    "                  \n",
    "        if epoch % 500 ==0:\n",
    "            saver.save(sess, './checkpoint_wgan_GP/generator.ckpt', global_step=epoch)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "# end time\n",
    "time_end = time.time()\n",
    "print('elapsed time：%.2f s.'%(time_end-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save losses and log\n",
    "with open('./trainingLog_wgan_GP/loss_variation.loss', 'wb') as l:\n",
    "    losses = np.array(losses)\n",
    "    pickle.dump(losses,l)\n",
    "    print('loss saved')\n",
    "    \n",
    "with open('./trainingLog_wgan_GP/generateLog.log', 'wb') as g:\n",
    "    pickle.dump(generateLog, g)\n",
    "    print('GenLog saved..')\n",
    "    \n",
    "# output\n",
    "with open('./trainingLog_wgan_GP/generateLog.log', 'rb') as f:\n",
    "    generateLog = pickle.load(f)\n",
    "    generateLog = np.array(generateLog)\n",
    "    showImg(generateLog,[-1],10)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "with open(r'./trainingLog_wgan_GP/loss_variation.loss','rb') as l:\n",
    "    losses = pickle.load(l)\n",
    "    fig, ax = plt.subplots(figsize=(20, 7))\n",
    "    plt.plot(losses.T[2],losses.T[0], label='Discriminator Loss')\n",
    "    plt.plot(losses.T[2],losses.T[1], label='Generator Loss')\n",
    "    plt.title(\"Training Losses\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image generation\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    meta_graph = tf.train.import_meta_graph('./checkpoint_wgan_GP/generator.ckpt-40000.meta')\n",
    "    meta_graph.restore(sess,tf.train.latest_checkpoint('./checkpoint_wgan_GP'))\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs_noise = graph.get_tensor_by_name(\"inputs_noise:0\")\n",
    "    d_outputs_fake = graph.get_tensor_by_name(\"generator/Tanh:0\")\n",
    "    sample_noise= np.random.normal(size=(2560, 128))\n",
    "    gen_samples = sess.run(d_outputs_fake,feed_dict={inputs_noise: sample_noise})\n",
    "    gen_samples = [(gen_samples[0:2561]+1)/2]\n",
    "    showImg(gen_samples, [0], 10)\n",
    "    for i in range(2560):\n",
    "        img=gen_samples[0][i]\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\"images_wgan_GP/car_%d.png\" % i)\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling CIFAR10 images and extract 2560 random images to calculate FID score\n",
    "# random.shuffle(C)\n",
    "# images=C[-2561:-1].reshape(-1,3,32,32).transpose((0,2,3,1))\n",
    "# for i in range(2560):\n",
    "#         img=images[i]\n",
    "#         plt.imshow(img)\n",
    "#         plt.axis('off')\n",
    "#         plt.savefig(\"shuffledCifar/car_%d.png\" % i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
